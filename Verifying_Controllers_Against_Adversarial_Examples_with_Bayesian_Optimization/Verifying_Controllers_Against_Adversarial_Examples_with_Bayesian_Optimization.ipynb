{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><a href=\"https://arxiv.org/abs/1802.08678\">\n",
    "Verifying Controllers Against Adversarial Examples with Bayesian Optimization</a></h1>\n",
    "Shromona Ghosh et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Summary</h2>\n",
    "\n",
    "* Use boolean combinations of smooth functions on the trajectories as safety specification\n",
    "\n",
    "* Use Baysesian Optimization to actively test the controller to find adversarial counterexamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Motivation</h2>\n",
    "\n",
    "* Conventional techniques in designing robust controllers rely on simple linear models of the underlying system.\n",
    "    * Either overly conservative\n",
    "    \n",
    "    * Or inaccurate due to overapproximation, e.g. cannot capture nonlinear effects\n",
    "    \n",
    "* Reinforcement learning can generate high fidelity controllers\n",
    "    * No formal guarantees for safety\n",
    "\n",
    "* Formal safety certificates by using formal methods\n",
    "    * Curse of dimensionality\n",
    "    * Only use simple system dynamics\n",
    "    \n",
    "* Falsification tests the system in various environments seeking for adversarial examples\n",
    "    * Perturbations must be meaningful for dynamic systems\n",
    "* Test black-box systems by using smart search techinques\n",
    "    * Sequential search algorithms based on heuristics, e.g. CMA-ES, Simulated Annearling, does not utilize information of previous simulations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Problem Formulation</h2>\n",
    "\n",
    "* A closed-loop system uses a model parameterizing environment uncertainty with $w\\in\\mathbb{W}$\n",
    "\n",
    "* If the system remain safe under all uncertain scenarios, then it satisfiies the safety specfication $\\forall w\\in\\mathbb{W}, \\varphi(w)>0$\n",
    "\n",
    "* Test wether there is an adversarial example $w\\in\\mathbb{W}$ s.t. $\\varphi(w)<0$ and minimize the test cost, e.g. number of simulations\n",
    "$$argmin_{w\\in\\mathbb{W}} \\varphi(w)$$\n",
    "\n",
    "* Key problem is that functional dependence $\\varphi(w)$ and $w$ is unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Background</h2>\n",
    "\n",
    "* Safety Specification\n",
    "$$\\varphi:= \\mu|\\neg\\mu|\\varphi_1\\vee\\varphi_2|\\varphi_1\\wedge\\varphi_2$$\n",
    "where $\\mu:\\Xi\\rightarrow\\mathbb{R}$ returns the 'robustness' of a trajectory $\\xi\\in\\Xi$\n",
    "\n",
    "$$\\mu(\\xi):=\\mu(\\xi), (\\varphi_1\\vee\\varphi_2)(\\xi):=min(\\varphi_1, \\varphi_2)),\\\\\n",
    "  \\neg\\mu(\\xi):=-\\mu(\\xi), (\\varphi_1\\wedge\\varphi_2):=max(\\varphi_1, \\varphi_2)),$$\n",
    "  \n",
    "* Gaussian Process\n",
    "    * $\\hat{\\\\\\mu}(w)$ is the observed target function $\\mu(w)$ with Gaussian noise $\\hat{\\\\\\mu}(w)=\\mu(w)+\\omega$ where $\\omega\\sim\\mathcal{N}(0,\\sigma^2)$.\n",
    "    * Given $n$ observation $y_n=(\\hat{\\\\\\mu}(w_1), \\hat{\\\\\\mu}(w_2),\\ldots, \\hat{\\\\\\mu}(w_n))$ and their corresponding input $W_n=\\{w_1, w_2,\\ldots, w_n\\}$, the posterior over function $\\mu(w)$ has expectation $m_n(w)$, covariance $k_n(w,w) and variance $\\sigma_n(w)$ where\n",
    "\n",
    "\\begin{eqnarray}\n",
    "m_n(w)&=&k_n(w)(K_n+I_n\\sigma^2)^{-1}y_n\\\\\n",
    "k_n(w,w')&=&k(w,w')-k_n(w)(K_n+I_n\\sigma^2)^{-1}k^T_n(w')\\\\\n",
    "\\sigma^2_n(w)&=&k_n(w,w')\\\\\n",
    "\\\\\n",
    "k_n(w)&=&[k(w,w_1),\\ldots, k(w,w_n)]\\\\\n",
    "[K_n](i,j)&=&k(w_i,w_j)\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "* Bayesian Optimization\n",
    "    * The optimization function based on GP is $w_n=argmin_{w\\in\\mathbb{W}} m_{n-1}(w)-\\beta^{1/2}_n\\sigma_{n-1}(w)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Approach</h2>\n",
    "\n",
    "\n",
    "* `Parse Tree` $\\mathcal{T}$: given a specification formula $\\varphi$, the corresponding parse tree $\\mathcal{T}$ has leaf nodes that corresponding to function predicates(atomics), while other nodes are max(disjunctions) and min(conjunctions) (and negation????). Use the quantified specification to represent the tree\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\varphi(w)&=&(\\mu_1\\wedge\\mu_2)\\vee\\ldots\\\\\n",
    "&\\Rightarrow& max(min\\ldots)\\\\\n",
    "\\mathcal{T}(\\mu_1(w),\\ldots, \\mu_q(w))&=&\\varphi(w) \n",
    "\\end{eqnarray}\n",
    "\n",
    "* The distribution of the tree is bounded with high probability by the lower-confidence interval of one of the predicates. Consider the **lower bounds** within the confidence intervals of each $\\mu_i$ in the tree \n",
    "$$l_1=m^i_{n-1}(w)-\\beta_n^{1/2}\\sigma^i_{n-1}(w)$$\n",
    "\n",
    "* Then a heuristic solution to BO optimization is to find a $w$ that maximally approaching the lower bounds of the confidence intervals of all the predicates. \n",
    "$$w=argmin_{w\\in\\mathbb{W}} \\varphi(l_1(w),l_2(w),\\ldots,l_q(w))$$\n",
    "After $w$ is solved, add $w$ back to $W$ and start next propagation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
