{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><a href=\"https://arxiv.org/abs/1709.09130\">\n",
    "A Simple Neural Network Module for Relational Reasoning</a></h1>\n",
    "Adam Santoro et al.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Summary</h2>\n",
    "\n",
    "* Relation Networks (RNs) can be used as a simple plug-and-play module to solve problems that fundamentally hinge on relational reasoning.\n",
    "\n",
    "* A deep learning architecture equipped with an RN module can implicitly discover and learn to reason about entities and their relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Introduction</h2>\n",
    "\n",
    "* Reasoning about the relations is central to general intelligence.\n",
    "\n",
    "* Symbolic approaches to artificial intelligence suffer from low robustness to small tasks and input variations.\n",
    "\n",
    "* Deep learning, statistical learning, etc. struggle in data-poor problems where underlying structure is characterized by sparse but complex relations.\n",
    "\n",
    "* Seemly simple relational inferences are remarkably difficult for powerful neural network architectures such as CNNs and MLPs.\n",
    "    \n",
    "* **Relation Network (RN)** in this paper is a general solution to relational reasoning in NN. \n",
    "    * Focus on flexible relational reasoning.\n",
    "    * Influence upstream representations in CNNs and LSTMs to produce __(who???)__ implicit object-like representations\n",
    "    * Outperforms general architectures in visual question answering (QA) dataset that demands rich relational reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Relation Networks</h2>\n",
    "\n",
    "* RN is a NN module with a structure inferring relations.\n",
    "* The capacity of capturing relations is the nature of RN.\n",
    ">Just like the CNN can capture spatial, translation invariant properties, RNN can reason sequential dependencies.\n",
    "\n",
    "* The simpliest form of an RN is a composite function $RN(O)=f_\\phi(\\sum_{i,j} g_\\theta(o_i, o_j))$\n",
    ">* Input is a set of \"objects\" $O=\\{o_1, o_2,\\ldots, o_n\\}, o_i\\in\\mathbb{R}^m$ is the $i^{th}$ object<br>\n",
    " * $f_\\phi$ can $g_\\theta$ are MLPs with parameters $\\phi$ and $\\theta$.<br>\n",
    " * Input includes all $(o_i, o_j)$ pairs thus the RN considers the potential relations between all object pairs.<br>\n",
    " * The cost is determined by all object pairs of the entire object set instead of individuals.<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tasks</h2>\n",
    "\n",
    "RN-augmented network is applied to different domains\n",
    "\n",
    "* **CLEVR**: visual QA dataset\n",
    "    * Architectures must reason the relations over the feawtures in the visual inputs, language inputs, and their conjunction.\n",
    "    * Contains images of 3D-rendered objects asscociated with questions such as querying the color and compare the material.\n",
    "    * Powerful QA architectures in <a href=\"https://arxiv.org/abs/1511.02274\">existing work</a> cannot solve certain tasks that require ability of handling relational aspects.\n",
    "    * Two versions:\n",
    "        * Pixel version: treat images as 2D pixel form.\n",
    "        * State description version: treat images as 3D form and provide different aspects of information.\n",
    "<img src=\"fig1.png\"></img>\n",
    "\n",
    "* **Sort-of-CLEVER**: separates relational and non-relational questions\n",
    "    * Chose from 6 different shapes and 6 colors.\n",
    "    * Questions are hard-coded as fixed-length binary string.\n",
    "    * 10 relational questions and 10 non-relational questions are asked.\n",
    "    \n",
    "* **bAbI**: pure text-based QA dataset\n",
    "    * 20 tasks each corresponding to a particular type of reasoning, e.g. deduction, induction, counting, ...\n",
    "    * Each question is associated with a set of support set of facts as prior.\n",
    "\n",
    "* **Dynamic physical systems**: simulated physical mass-spring systems using the MuJoCo engine\n",
    "    * 20 balls on a table, where some move indepently while others are randomly connected in pairs by force\n",
    "    * Create a randomly connected graph.\n",
    "    * Inputs are the color of the balls and the positions across multiple sequential frames.\n",
    "    * Two separated questions:\n",
    "        * infer the absence of connections by observing the colors and coordinate positions across multiple sequential frames\n",
    "        * count the number of graphs by observing the colors and coordinate positions across multiple sequential frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Models</h2>\n",
    "\n",
    "RNs operate on objects. The learning process induces upstream to produce useful \"object\" from distributed representations.\n",
    "<img src=\"fig2.png\"></img>\n",
    "* **Dealing with pixels**: use CNN to process pixels and the final output of the convoluted layers is the object for RN.\n",
    "\n",
    "* **Dealing with natural language**:\n",
    "    * first identify up to 20 sentences in the support set that were immediately prior to the probe question\n",
    "    * tag their relative position in the support set\n",
    "    * use LSTM to process those sentences and the final state is the object for RN.\n",
    "\n",
    "* **Dealing with questions**: use LSTM to process question words and output the final state to the RN as question embedding.\n",
    "\n",
    "* **Model details**:\n",
    "    * **CLEVER** task\n",
    "        * 64 mini-batches and distributed traning with 10 workers synchronously updating a central parameter server.\n",
    "        * Image processing: CNN with 4 conv layers each with 24 kernels, ReLU non-linearities and batch normalization\n",
    "        * Questions processing: 128-unit LSTM; 32 unite word lookup embedding;\n",
    "        * RN: 4 layer MLP with 256 units per layer and ReLU non-linearities for $g_\\theta$; 3 layer MLP with 256,256($50%$ dropout), and 29 units with ReLU non-linearities for $f_\\theta$; softmax output with cross-entropy loss function optimized by Adam optimizer with learning rate of $2.5e^{-4}$. \n",
    "        \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Results</h2>\n",
    "\n",
    "<h3>CLEVER pixels version</h3>\n",
    "\n",
    "<img src=\"./fig3.png\"></img>\n",
    "\n",
    "RN architecture exceeds the best model mostly in the compare attrivute and count categories.\n",
    "\n",
    "<img src=\"./fig4.png\"></img>\n",
    "\n",
    "<h3>CLEVER state description version</h3>\n",
    "\n",
    "RN model achieved $96.4%$ accuracy which shows that the model can be generalised beyond visual problems. It can learn and reason about object relations while the true nature of the object is still agnostic.\n",
    "\n",
    "<h3>Sort-of-CLEVER from pixels</h3>\n",
    "\n",
    "In those tasks, the difficulty in parsing the question is much lighter. However, RN still achieved above $94%$ accuracy both in relational and non-relational questions. In comparison, CNN with MLP only achieved $63%$ in the relational questions, especially $52.3%$ in \"closest-to\" or \"furthest-from\" kind of heavily relational questions. \n",
    "\n",
    "<h3>bAbI</h3>\n",
    "\n",
    "The RN model succeeded on $18/20$ tasks and has lower error rate ($2.1%$) on the basic induction task than Sparse DNC($54%$), DNC($55.1%$), and EntNet($52.1%$). And in tasks that it failed, it almost reached the success threshold.\n",
    "\n",
    "<h3>Dynamic physical systems</h3>\n",
    "\n",
    "The RN model correctly classified all the connections in $93%$ of the sample scenes in the connection inference task and $95%$ in counting task. In comparison, MLP with comparable number of parameters was unable to perform as well as RN in both tasks at the same time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Discussion</h2>\n",
    "\n",
    "Experiments showed that RN module inclusion in simple CNN and LSTM based model can raise the performance. The author speculated that it was the RN module that freed the CNN to more focus on processing local spatial structure, thus processing and reasoning are distinct from each other.\n",
    "\n",
    "Future work includes apply RNs to problems that can benefit from structure learning and exploitation such as rich scene understanding in RL agents and abstract problem solving.\n",
    "\n",
    "RN modules can be further optimized, e.g. exploit prior knowledge, omit weak and non-existing relations, set up attention mechanism to allocate compuational power to important relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
